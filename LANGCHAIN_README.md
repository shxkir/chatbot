# Complete LangChain PDF-RAG Chatbot

## âœ… What's Been Built

A production-ready PDF chatbot with:

- **Frontend**: Next.js with TypeScript (localhost:3001)
- **Backend**: Express + LangChain (localhost:5001)
- **Vector DB**: Pinecone with namespaced documents
- **AI**: OpenAI embeddings + ChatGPT RAG

## ğŸ¯ Features Implemented

### Backend Features
âœ… **POST /api/langchain/upload** - PDF upload + embedding
  - PDF text extraction (pdf-parse)
  - Smart chunking with RecursiveCharacterTextSplitter
  - OpenAI embeddings (text-embedding-3-small)
  - Pinecone storage with namespace `pdf_<timestamp>`

âœ… **POST /api/langchain/query** - RAG-powered chat
  - Similarity search in Pinecone
  - Context retrieval (top 5 chunks)
  - ChatGPT response with references
  - Relevance scores included

âœ… **CORS configured** for localhost:3001
âœ… **Error handling** with descriptive messages
âœ… **Environment variables** for all configuration

### Frontend Features
âœ… **Upload Page** (/langchain-upload)
  - Drag-and-drop PDF interface
  - Progress indicators
  - File size display
  - Success/error states

âœ… **Chat Page** (/langchain-chat)
  - ChatGPT-style UI
  - Message history
  - Loading animations
  - Reference display with scores

âœ… **API Client** with TypeScript types
âœ… **Custom hooks** for state management
âœ… **Responsive design**

## ğŸ“ Project Structure

```
chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ env.js                          # Environment configuration
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ langchain-upload.js            # LangChain upload endpoint
â”‚   â”‚   â””â”€â”€ langchain-query.js             # LangChain query endpoint
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ langchain.js                   # LangChain PDF processing & RAG â­
â”‚   â”‚   â”œâ”€â”€ embeddings.js                  # Original OpenAI service
â”‚   â”‚   â”œâ”€â”€ pinecone.js                    # Original Pinecone service
â”‚   â”‚   â””â”€â”€ pdf.js                         # Original PDF service
â”‚   â”œâ”€â”€ server.js                          # Express server with both routes
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ .env.local                         # Your API keys
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ langchain-upload/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ page.tsx              # LangChain upload page â­
â”‚   â”‚   â”‚   â””â”€â”€ langchain-chat/
â”‚   â”‚   â”‚       â””â”€â”€ page.tsx              # LangChain chat page â­
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ LangChainUploader.tsx     # Upload component â­
â”‚   â”‚   â”‚   â””â”€â”€ LangChainChat.tsx         # Chat component â­
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â””â”€â”€ useLangChainChat.ts       # Chat hook â­
â”‚   â”‚   â””â”€â”€ lib/
â”‚   â”‚       â”œâ”€â”€ langchainApi.ts           # LangChain API client â­
â”‚   â”‚       â””â”€â”€ backendApi.ts             # Original API client
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ .env.local
â”‚
â”œâ”€â”€ LANGCHAIN_GUIDE.md                     # Comprehensive guide â­
â”œâ”€â”€ LANGCHAIN_README.md                    # This file â­
â”œâ”€â”€ QUICK_START.md                         # Quick setup guide
â””â”€â”€ package.json                           # Root package with scripts

â­ = New LangChain files
```

## ğŸš€ Quick Start (3 Steps)

### Step 1: Add API Keys

Edit `backend/.env.local`:
```bash
OPENAI_API_KEY=sk-proj-xxxxx        # Your actual OpenAI key
PINECONE_API_KEY=pcsk-xxxxx         # Your actual Pinecone key
PINECONE_INDEX_NAME=pdf-chatbot     # Your index name
```

### Step 2: Create Pinecone Index

Go to https://www.pinecone.io/ and create an index:
- **Name**: `pdf-chatbot`
- **Dimensions**: `1536`
- **Metric**: `cosine`

### Step 3: Start Servers

```bash
# Install dependencies (first time only)
npm install

# Start both servers
npm run dev
```

### Step 4: Use the App

- **Upload PDF**: http://localhost:3001/langchain-upload
- **Chat**: http://localhost:3001/langchain-chat

## ğŸ“¡ API Endpoints

### Backend Routes

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check |
| `/api/langchain/upload` | POST | Upload PDF with LangChain |
| `/api/langchain/query` | POST | Query with RAG |
| `/api/upload` | POST | Original upload (no LangChain) |
| `/api/query` | POST | Original query (no LangChain) |

### LangChain Upload Example

```bash
curl -X POST http://localhost:5001/api/langchain/upload \
  -F "file=@document.pdf"
```

Response:
```json
{
  "message": "PDF processed successfully",
  "namespace": "pdf_1699564123456",
  "fileName": "document.pdf",
  "chunksIndexed": 127
}
```

### LangChain Query Example

```bash
curl -X POST http://localhost:5001/api/langchain/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is this document about?",
    "namespace": "pdf_1699564123456"
  }'
```

Response:
```json
{
  "question": "What is this document about?",
  "reply": "Based on the provided context...",
  "references": [
    {
      "rank": 1,
      "score": 0.89,
      "textPreview": "This document discusses...",
      "source": "document.pdf"
    }
  ],
  "namespace": "pdf_1699564123456"
}
```

## ğŸ”§ Dependencies Installed

### Backend (New)
```json
{
  "langchain": "^0.3.11",
  "@langchain/openai": "^0.3.23",
  "@langchain/pinecone": "^1.0.0",
  "@pinecone-database/pinecone": "^5.0.2"
}
```

All other dependencies remain the same.

## ğŸ¨ Frontend Pages

### Upload Page: /langchain-upload
- Modern gradient background
- Drag-and-drop PDF upload
- Real-time status updates
- Shows chunks indexed
- Auto-redirect to chat

### Chat Page: /langchain-chat
- ChatGPT-style interface
- Message bubbles
- Typing indicators
- Reference panel with scores
- Namespace display

## ğŸ’¡ How It Works

### Upload Flow
```
1. User uploads PDF â†’ Frontend sends to /api/langchain/upload
2. Backend extracts text with pdf-parse
3. LangChain RecursiveCharacterTextSplitter splits into chunks
4. OpenAI creates embeddings for each chunk
5. Store in Pinecone with namespace pdf_<timestamp>
6. Return namespace to frontend
```

### Query Flow
```
1. User asks question â†’ Frontend sends to /api/langchain/query
2. Backend embeds question with OpenAI
3. Pinecone similarity search (top 5 chunks)
4. Build context from retrieved chunks
5. ChatGPT generates answer with context
6. Return answer + references with scores
```

## ğŸ”‘ Required Environment Variables

### Backend (.env.local)
```env
OPENAI_API_KEY=sk-proj-xxxxx          # Required
PINECONE_API_KEY=pcsk-xxxxx          # Required
PINECONE_INDEX_NAME=pdf-chatbot      # Required
```

### Frontend (.env.local)
```env
NEXT_PUBLIC_API_URL=http://localhost:5001  # Pre-configured
```

## ğŸ§ª Testing

### Test Backend Health
```bash
curl http://localhost:5001/health
# Expected: {"status":"ok"}
```

### Test LangChain Upload
```bash
curl -X POST http://localhost:5001/api/langchain/upload \
  -F "file=@sample.pdf"
```

### Test LangChain Query
```bash
curl -X POST http://localhost:5001/api/langchain/query \
  -H "Content-Type: application/json" \
  -d '{"question":"test","namespace":"pdf_1699564123456"}'
```

## ğŸ“š Key LangChain Features

### RecursiveCharacterTextSplitter
- Intelligently splits text at natural boundaries
- Preserves context with overlap
- Configurable chunk size (1500 chars by default)

### PineconeStore
- LangChain integration for Pinecone
- Automatic embedding and storage
- Similarity search with scores

### OpenAI Integration
- Embeddings: text-embedding-3-small (1536 dimensions)
- Chat: gpt-4o-mini (fast and cost-effective)
- Temperature: 0.2 (focused answers)

### RAG Pipeline
1. Embed user question
2. Retrieve similar chunks
3. Build context prompt
4. Generate answer with ChatGPT
5. Return with source references

## ğŸ†š Two Implementations Available

You now have **TWO working implementations**:

### Original (Without LangChain)
- Routes: `/api/upload`, `/api/query`
- Custom chunking function
- Direct OpenAI + Pinecone integration
- Pages: `/upload`, `/chat`

### LangChain (New) â­
- Routes: `/api/langchain/upload`, `/api/langchain/query`
- RecursiveCharacterTextSplitter
- LangChain abstractions
- Pages: `/langchain-upload`, `/langchain-chat`

Both work independently! Use whichever you prefer.

## ğŸ› Troubleshooting

**"Network error contacting /api"**
- Ensure backend is running: `npm run dev:backend`
- Check port 5001 is free: `lsof -i :5001`

**"OPENAI_API_KEY is not set"**
- Add your key to `backend/.env.local`
- Restart the backend server

**"Namespace not found"**
- Upload a PDF first
- Check the namespace value from upload response

**CORS errors**
- Verify `FRONTEND_URL` in backend .env
- Should be `http://localhost:3001`

## ğŸ“– Documentation

- **LANGCHAIN_GUIDE.md** - Complete guide with examples
- **QUICK_START.md** - Quick setup reference
- **SETUP_GUIDE.md** - Original Express setup
- **CHANGES_SUMMARY.md** - What was changed

## ğŸ¯ Next Steps

1. **Add API keys** to `backend/.env.local`
2. **Create Pinecone index** (1536 dimensions, cosine metric)
3. **Start servers**: `npm run dev`
4. **Upload PDF**: http://localhost:3001/langchain-upload
5. **Start chatting**: Ask questions about your PDF!

## ğŸ’° Cost Estimates

Per 100-page PDF:
- **Embeddings**: ~$0.01
- **Chat queries**: ~$0.005 per question
- **Pinecone**: Free tier includes 100K vectors

## ğŸš€ Production Ready

The app includes:
- âœ… Error handling
- âœ… Input validation
- âœ… CORS configuration
- âœ… Environment variables
- âœ… TypeScript types
- âœ… Loading states
- âœ… Responsive design

For production deployment, see LANGCHAIN_GUIDE.md.

## ğŸ‰ You're Ready!

Your complete LangChain PDF-RAG chatbot is ready to use!

1. Add your API keys to `backend/.env.local`
2. Run `npm run dev`
3. Go to http://localhost:3001/langchain-upload
4. Upload a PDF and start chatting!

Need help? Check LANGCHAIN_GUIDE.md for detailed documentation.
